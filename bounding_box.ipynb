{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-DO2WYEjrgrY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LTatr5cMv2-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e38d9cd-f1fa-4003-8fe9-5587ee7eb422"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8e2YDlyvym6",
        "outputId": "e411acc5-56ca-42ef-84cb-964daf28565e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (8.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cueyt1iTv35N",
        "outputId": "ca75fb89-da23-454b-e8cd-da15591e1703"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 4,850 kB of archives.\n",
            "After this operation, 16.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n",
            "Fetched 4,850 kB in 1s (5,163 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 122545 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2build2) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "seKa48957iwa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source = '/content/drive/MyDrive/CAPSTONE PROJECT BANGKIT/skincare product dataset'\n",
        "#path into train and test images\n",
        "train_images = os.path.join(source, 'images')\n",
        "train_annotations = os.path.join(source, 'mask')"
      ],
      "metadata": {
        "id": "bKRaSWRq7k83"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Contents of base directory:\")\n",
        "print(os.listdir(source))\n",
        "\n",
        "print(\"\\nContents of train directory:\")\n",
        "print(os.listdir(f'{source}/train_images'))\n",
        "\n",
        "print(\"\\nContents of validation directory:\")\n",
        "print(os.listdir(f'{source}/train_annotations'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dpu9g4ZIHPW",
        "outputId": "76eb537c-b054-469e-9b56-57006bc7a2a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of base directory:\n",
            "['train_images', 'train_annotations', 'images', 'mask']\n",
            "\n",
            "Contents of train directory:\n",
            "['clear.jpeg', 'photo1684971609.jpeg', 'photo1684971618.jpeg', 'photo1684971633.jpeg', 'photo1684971642.jpeg', 'photo1684971652.jpeg', 'photo1684971668.jpeg', 'photo1684971800.jpeg']\n",
            "\n",
            "Contents of validation directory:\n",
            "['clear.jpeg', 'photo1684971609 - Copy.jpeg', 'photo1684971618 - Copy.jpeg', 'photo1684971633 - Copy.jpeg', 'photo1684971642 - Copy.jpeg', 'photo1684971668 - Copy.jpeg', 'photo1684971800 - Copy.jpeg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_image = sorted(os.listdir(train_images))\n",
        "sorted_mask = sorted(os.listdir(train_annotations))"
      ],
      "metadata": {
        "id": "3aGLR1GOI-d2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 128"
      ],
      "metadata": {
        "id": "lH-hBD-eKJC_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_segmented_img(img):\n",
        "    # Membuat array kosong dengan ukuran (img_size, img_size, 1) untuk menyimpan label-label segmentasi.\n",
        "    labels = np.zeros((img_size, img_size, 1))\n",
        "    \n",
        "    # Mengubah ukuran gambar menjadi (img_size, img_size).\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    \n",
        "    # Mengambil saluran pertama dari gambar.\n",
        "    img = img[:, :, 0]\n",
        "    \n",
        "    # Mengisi array labels dengan nilai 0 atau 1 berdasarkan piksel gambar.\n",
        "    # Jika nilai piksel tidak sama dengan 0, dianggap sebagai bagian tersegmentasi dan diberi nilai 1.\n",
        "    # Jika nilai piksel sama dengan 0, dianggap sebagai bagian tidak tersegmentasi dan diberi nilai 0.\n",
        "    labels[:, :, 0] = (img != 0).astype(int)\n",
        "\n",
        "    # Mengembalikan array labels sebagai hasil dari fungsi.\n",
        "    return labels"
      ],
      "metadata": {
        "id": "bAnB3CtUVy99"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "# Iterasi melalui setiap indeks dalam daftar file gambar di direktori train_images.\n",
        "for index in range(len(os.listdir(train_images))):\n",
        "    # Membaca gambar menggunakan OpenCV dari path yang diberikan oleh os.path.join.\n",
        "    img = cv2.imread(os.path.join(train_images, sorted_image[index]))\n",
        "    \n",
        "    # Mengubah gambar menjadi skala abu-abu.\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Melakukan thresholding pada gambar menggunakan nilai ambang 150.\n",
        "    # Piksel dengan intensitas di atas ambang akan menjadi putih, sedangkan yang di bawah ambang akan menjadi hitam.\n",
        "    ret, img = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "    \n",
        "    # Mengubah ukuran gambar menjadi ukuran (img_size, img_size).\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    \n",
        "    # Menambahkan dimensi tambahan pada gambar menggunakan np.expand_dims.\n",
        "    # Dalam konteks ini, dimensi tambahan ditambahkan di akhir untuk sesuai dengan format data model yang diharapkan.\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    \n",
        "    # Normalisasi gambar dengan membaginya dengan 255.\n",
        "    img = img / 255\n",
        "    \n",
        "    # Membaca masker gambar yang sesuai dengan gambar yang sedang diproses.\n",
        "    annotation = cv2.imread(os.path.join(train_annotations, sorted_mask[index]))\n",
        "    \n",
        "    # Mengubah masker menjadi skala abu-abu.\n",
        "    annotation = cv2.cvtColor(annotation, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Mengubah ukuran masker menjadi ukuran (img_size, img_size).\n",
        "    annotation = cv2.resize(annotation, (img_size, img_size))\n",
        "    \n",
        "    # Membuat saluran warna untuk masker dengan mengulang saluran abu-abu tiga kali.\n",
        "    annotation = np.stack((annotation,)*3, axis=-1)\n",
        "    \n",
        "    # Menggunakan fungsi get_segmented_img untuk menghasilkan label segmentasi dari masker.\n",
        "    annotation = get_segmented_img(annotation)\n",
        "    \n",
        "    # Menambahkan gambar dan label segmentasi ke dalam daftar x dan y, masing-masing.\n",
        "    x.append(img)\n",
        "    y.append(annotation)"
      ],
      "metadata": {
        "id": "O_RVc0WQW-PW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Dataset\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, random_state = 1)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "2vDLG2_ZK7Z3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZU9MX-aK-tO",
        "outputId": "9db71919-5ad1-4e3a-f8ee-a27c97c7ecac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17, 128, 128, 1)\n",
            "(5, 128, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "inputs = Input((img_size, img_size, 1))\n",
        "\n",
        "conv1 = Conv2D(64, 3, activation= 'relu', kernel_initializer='he_normal',padding = 'same')(inputs)\n",
        "conv1 = Conv2D(64, 3, activation= 'relu',kernel_initializer='he_normal', padding = 'same')(conv1)\n",
        "pool1 = MaxPooling2D(2,2)(conv1)\n",
        "\n",
        "conv2 = Conv2D(128, 3, activation= 'relu', kernel_initializer='he_normal', padding = 'same')(pool1)\n",
        "conv2 = Conv2D(128, 3, activation= 'relu', kernel_initializer='he_normal',padding = 'same')(conv2)\n",
        "pool2 = MaxPooling2D(2,2)(conv2)\n",
        "\n",
        "conv3 = Conv2D(256, 3, activation= 'relu', kernel_initializer='he_normal',padding = 'same')(pool2)\n",
        "conv3 = Conv2D(256, 3, activation= 'relu',kernel_initializer='he_normal', padding = 'same')(conv3)\n",
        "pool3 = MaxPooling2D(2,2)(conv3)\n",
        "\n",
        "conv4 = Conv2D(512, 3, activation= 'relu', kernel_initializer='he_normal',padding = 'same')(pool3)\n",
        "conv4 = Conv2D(512, 3, activation= 'relu',kernel_initializer='he_normal', padding = 'same')(conv4)\n",
        "pool4 = MaxPooling2D(2,2)(conv4)\n",
        "\n",
        "conv5 = Conv2D(1024, 3, activation= 'relu',kernel_initializer='he_normal', padding = 'same')(pool4)\n",
        "conv5 = Conv2D(1024, 3, activation= 'relu', kernel_initializer='he_normal',padding = 'same')(conv5)\n",
        "dropout5 = Dropout(0.5)(conv5)\n",
        "\n",
        "up6 = Conv2D(512, 2, activation = 'relu', kernel_initializer='he_normal',padding = 'same')(UpSampling2D(size = (2,2))(dropout5))\n",
        "merge6 = concatenate([conv4,up6], axis = 3)\n",
        "conv6 = Conv2D(512, 3, activation = 'relu', kernel_initializer='he_normal',padding = 'same')(merge6)\n",
        "conv6 = Conv2D(512, 3, activation = 'relu', kernel_initializer='he_normal',padding = 'same')(conv6)\n",
        "\n",
        "up7 = Conv2D(256, 2, activation = 'relu', kernel_initializer='he_normal',padding = 'same')(UpSampling2D(size = (2,2))(conv6))\n",
        "merge7 = concatenate([conv3,up7], axis = 3)\n",
        "conv7 = Conv2D(256, 3, activation = 'relu', kernel_initializer='he_normal', padding = 'same')(merge7)\n",
        "conv7 = Conv2D(256, 3, activation = 'relu',kernel_initializer='he_normal', padding = 'same')(conv7)\n",
        "\n",
        "up8 = Conv2D(128, 2, activation = 'relu', kernel_initializer='he_normal',padding = 'same')(UpSampling2D(size = (2,2))(conv7))\n",
        "merge8 = concatenate([conv2,up8], axis = 3)\n",
        "conv8 = Conv2D(128, 3, activation = 'relu', kernel_initializer='he_normal',padding = 'same')(merge8)\n",
        "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same')(conv8)\n",
        ",\n",
        "up9 = Conv2D(64, 2, activation = 'relu', kernel_initializer='he_normal', padding = 'same')(UpSampling2D(size = (2,2))(conv8))\n",
        "merge9 = concatenate([conv1,up9], axis = 3)\n",
        "conv9 = Conv2D(64, 3, activation = 'relu',kernel_initializer='he_normal', padding = 'same')(merge9)\n",
        "conv9 = Conv2D(64, 3, activation = 'relu',kernel_initializer='he_normal', padding = 'same')(conv9)\n",
        "\n",
        "conv9 = Conv2D(2, 3, activation = 'relu', kernel_initializer='he_normal',padding = 'same')(conv9)\n",
        "conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "     \n",
        "model = Model(inputs=inputs, outputs=conv9)\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate = 1e-4),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "    \n",
        "model.summary()\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syuZMp5BG2V_",
        "outputId": "39025170-c63a-4773-fe96-dff11d7bc182"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 128, 128, 64  640         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 128, 128, 64  36928       ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 64, 64, 64)   0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 64, 64, 128)  73856       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 64, 64, 128)  147584      ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0          ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 256)  590080      ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0          ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 512)  2359808     ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 512)   0           ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 8, 8, 1024)   4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 8, 8, 1024)   9438208     ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 8, 8, 1024)   0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 16, 16, 1024  0           ['dropout[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 512)  2097664     ['up_sampling2d[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 16, 16, 1024  0           ['conv2d_7[0][0]',               \n",
            "                                )                                 'conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 512)  2359808     ['conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 512)  0          ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 256)  524544      ['up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 32, 32, 512)  0           ['conv2d_5[0][0]',               \n",
            "                                                                  'conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 32, 32, 256)  1179904     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 32, 32, 256)  590080      ['conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 256)  0          ['conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 64, 64, 128)  131200      ['up_sampling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_3[0][0]',               \n",
            "                                                                  'conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 64, 64, 128)  295040      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 64, 64, 128)  147584      ['conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 12  0          ['conv2d_18[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 128, 128, 64  32832       ['up_sampling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_1[0][0]',               \n",
            "                                8)                                'conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 128, 128, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 128, 128, 64  36928       ['conv2d_20[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 128, 128, 2)  1154        ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,031,682\n",
            "Trainable params: 31,031,682\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          epochs=10,\n",
        "          steps_per_epoch=500,\n",
        "          validation_data=(x_test, y_test),\n",
        "          validation_steps=300,\n",
        "          shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D42veQdKEJ_",
        "outputId": "ec381b37-8644-4bf6-80d3-d20daa446baa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "170/500 [=========>....................] - ETA: 14s - loss: 0.2781 - accuracy: 0.9046"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 5000 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 300 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r500/500 [==============================] - 30s 16ms/step - loss: 0.2781 - accuracy: 0.9046 - val_loss: 0.0000e+00 - val_accuracy: 0.9691\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa69e2a9e10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('bounding_box.h5')"
      ],
      "metadata": {
        "id": "lckv4EKcMmDV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('bounding_box.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tYqGp2DKRm--",
        "outputId": "75bd295f-fdfe-4108-84f4-b953152c3d86"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4ce88fb2-99a4-4bdc-9273-5281783f933d\", \"bounding_box.h5\", 372583008)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}